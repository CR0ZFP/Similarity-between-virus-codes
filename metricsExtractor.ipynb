{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ha nincs letöltve a python kernel kérem töltse le vagy az extensionok-ből vagy a microsoft store-ból\n",
    "Ha a jupiter notebook sincs letöltve, kérem azt is töltse le az extensionok-ből\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Itt láthat kikommentezett részeket, ha ezek a libary-k nincsenek meg akkor ezeket is fel kell pipelni. Csak vegye ki a kommentet és úgy futtassa le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install pefile\n",
    "import os\n",
    "import hashlib\n",
    "import math\n",
    "import pefile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_size(filepath):\n",
    "    return os.path.getsize(filepath)\n",
    "\n",
    "\n",
    "\"\"\"\"\"\n",
    "def calculate_entropy(section_data):\n",
    "    byte_freq = [0] * 256\n",
    "    for byte in section_data:\n",
    "        byte_freq[byte] += 1\n",
    "    entropy = 0\n",
    "    for freq in byte_freq:\n",
    "        if freq > 0:\n",
    "            p_x = freq / len(section_data)\n",
    "            entropy -= p_x * math.log2(p_x)\n",
    "    return entropy\n",
    "\"\"\"\"\"\n",
    "\n",
    "def calculate_entropy(data):\n",
    "    if isinstance(data, bytes):  # Ha a bemenet bytes típusú, alakítsd listává\n",
    "        data = list(data)\n",
    "        \n",
    "    byte_freq = [0] * 256\n",
    "    for byte in data:\n",
    "        byte_freq[byte] += 1\n",
    "    entropy = 0\n",
    "    for freq in byte_freq:\n",
    "        if freq > 0:\n",
    "            p_x = freq / len(data)\n",
    "            entropy -= p_x * math.log2(p_x)\n",
    "    return entropy\n",
    "\n",
    "def calculate_file_entropy(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        file_data = f.read()  # Fájl teljes tartalmának beolvasása\n",
    "    return calculate_entropy(file_data)\n",
    "\n",
    "def extract_sections(pe):\n",
    "    section_features = []\n",
    "    for section in pe.sections:\n",
    "        section_features.append({\n",
    "            \"section_name\": section.Name.decode('utf-8', errors='ignore').strip(),\n",
    "            \"section_size\": section.SizeOfRawData,\n",
    "            \"section_entropy\": calculate_entropy(section.get_data()),\n",
    "            \"section_characteristics\": section.Characteristics\n",
    "        })\n",
    "    return section_features\n",
    "\n",
    "def extract_imports(pe):\n",
    "    if hasattr(pe, \"DIRECTORY_ENTRY_IMPORT\"):\n",
    "        return sum(len(entry.imports) for entry in pe.DIRECTORY_ENTRY_IMPORT)\n",
    "    return 0\n",
    "\n",
    "def extract_exports(pe):\n",
    "    if hasattr(pe, \"DIRECTORY_ENTRY_EXPORT\"):\n",
    "        return len(pe.DIRECTORY_ENTRY_EXPORT.symbols)\n",
    "    return 0\n",
    "\n",
    "def calculate_hash(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        file_data = f.read()\n",
    "        md5_hash = hashlib.md5(file_data).hexdigest()\n",
    "        sha256_hash = hashlib.sha256(file_data).hexdigest()\n",
    "    return md5_hash, sha256_hash\n",
    "\n",
    "def extract_import_details(pe):\n",
    "    imports = []\n",
    "    if hasattr(pe, \"DIRECTORY_ENTRY_IMPORT\"):\n",
    "        for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
    "            dll_name = entry.dll.decode('utf-8', errors='ignore')\n",
    "            for imp in entry.imports:\n",
    "                imports.append({\n",
    "                    \"dll\": dll_name,\n",
    "                    \"function\": imp.name.decode('utf-8', errors='ignore') if imp.name else None\n",
    "                })\n",
    "    return imports\n",
    "\n",
    "\n",
    "def extract_export_details(pe):\n",
    "    exports = []\n",
    "    if hasattr(pe, \"DIRECTORY_ENTRY_EXPORT\"):\n",
    "        for symbol in pe.DIRECTORY_ENTRY_EXPORT.symbols:\n",
    "            exports.append(symbol.name.decode('utf-8', errors='ignore') if symbol.name else None)\n",
    "    return exports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pe_features(filepath):\n",
    "    pe = pefile.PE(filepath)\n",
    "    file_hashes = calculate_hash(filepath)\n",
    "    sections = extract_sections(pe)\n",
    "\n",
    "    features = {\n",
    "        \"file name\": os.path.basename(filepath),\n",
    "        \"file_size\": file_size(filepath),   #a teljes exe merete byteban\n",
    "\n",
    "        \"file_entropy\": calculate_file_entropy(filepath), #a teljes exe entropiajat adja meg (magas entropia -> tomorites/titkositas -> potencionalis virus)\n",
    "\n",
    "        \"num_sections\": len(pe.sections),   #a fajl szekcioinak szamat mondja meg\n",
    "\n",
    "        \"entry_point\": pe.OPTIONAL_HEADER.AddressOfEntryPoint,  #A belépési pont címe hexadecimálisan, ||||TIPIKUS: 0x1000  # A `.text` szekcióban található |||| GYANUS: 0x3000  # Egy szokatlan szekcióban található\n",
    "\n",
    "        \"characteristics\": pe.FILE_HEADER.Characteristics,  #A fájl jellemzői ()\n",
    "\n",
    "        \"timestamp\": pe.FILE_HEADER.TimeDateStamp,  #A PE fájl időbélyege Unix timestampként (fajl forditasanak ideje)\n",
    "\n",
    "        \"md5_hash\": file_hashes[0],     #hash ertek szerint azonositja a teljes exet, ezek a train adatbazis hasonlosagat es a virusokat tartalmazo adatbazisokhoz jok (pl VirusTotal)\n",
    "        \"sha256_hash\": file_hashes[1],\n",
    "\n",
    "        \"num_imports\": extract_imports(pe), #importalt fuggvenyek szama\n",
    "\n",
    "        \"num_exports\": extract_exports(pe), #exportalt dllek szama,\n",
    "\n",
    "        \"import_details\": extract_import_details(pe),   #importalt fuggvenyek, dllek, stb nevei\n",
    "\n",
    "        \"export_details\": extract_export_details(pe)    #exportalt fuggvenyek, dllek, stb nevei\n",
    "    }\n",
    "\n",
    "    # Add section-based features dynamically\n",
    "    for i, section in enumerate(sections):  #minden sectionnek megmondja a nevét, entropyja, meretet, karakterisztikajat\n",
    "        features[f\"section_{i+1}_name\"] = section[\"section_name\"]\n",
    "        features[f\"section_{i+1}_size\"] = section[\"section_size\"]\n",
    "        features[f\"section_{i+1}_entropy\"] = section[\"section_entropy\"]\n",
    "        features[f\"section_{i+1}_characteristics\"] = section[\"section_characteristics\"]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset saved to malicious_data.csv\n"
     ]
    }
   ],
   "source": [
    "#test 1 exen\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "main_path = str(sys.argv[1])  # A bemeneti fájl elérési útvonala\n",
    "dataset_name = str(sys.argv[2])  # A kimeneti adathalmaz neve\n",
    "\n",
    "def process_single_file(filepath, label):\n",
    "    features = extract_pe_features(filepath)\n",
    "    features[\"malicious\"] = label  # Add label (0 for benign, 1 for malicious)\n",
    "    return features\n",
    "\n",
    "malicious_df = pd.DataFrame()\n",
    "#main_path=r\"C:\\Users\\Dogo\\Desktop\\exe\" #Teljes elérési útvonala a fertőzött exe fileoknak\n",
    "malicious_data_list = []\n",
    "\n",
    "for file in tqdm(os.listdir(main_path), desc=\"Processing files\", unit=\"file\"): #Kilistázunk minden exe file-t ami benne található\n",
    "\n",
    "    malicious_file_path= os.path.join(main_path,file) #Az útvonalt és a file nevét összemergeljük\n",
    "    with open (malicious_file_path, \"rb\") as file:\n",
    "        magic = file.read(2)\n",
    "    if magic == b\"MZ\": #Ha a file MZ-vel kezdődik, akkor exe file\n",
    "        malicious_data = process_single_file(malicious_file_path, label=1) #Elkezdjük feldolgozni az összeset amíg végig nem érünk rajtuk \n",
    "        malicious_data_list.append(malicious_data)  #Csakis kizárólag .exe filok feldolgozására alkalmas, kérem ezt vegye figyelembe\n",
    "    else:\n",
    "        print(f\"{file} is not an exe file\")\n",
    "\n",
    "\n",
    "malicious_df = pd.DataFrame(malicious_data_list)\n",
    "# Save to CSV for future use\n",
    "malicious_df.to_csv(dataset_name, index=False)\n",
    "print(\"Training dataset saved to {dataset_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
